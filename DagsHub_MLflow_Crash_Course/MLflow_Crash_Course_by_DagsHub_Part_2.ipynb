{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maulanaakbardj/MyWorkshop/blob/main/DagsHub_MLflow_Crash_Course/MLflow_Crash_Course_by_DagsHub_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><table>\n",
        "<tr>\n",
        "<td style=\"vertical-align: middle;\">\n",
        "<img src=\"https://drive.google.com/uc?id=1it6btONFfkZWFQavQCD6ibreILCqZ6s3\" height=\"350\"/>\n",
        "</td>\n",
        "<td style=\"vertical-align: middle;\">\n",
        "<img src=\"https://drive.google.com/uc?id=1g2O2UulZrAmUHqr69j-6K1HhdOIDae7u\" height=\"350\"/>\n",
        "</td>\n",
        "</tr>\n",
        "</table></center>\n",
        "\n",
        "<center><h1> üëã  Welcome to the Community MLFlow Crash Course by DagsHub!</h1>\n",
        "\n",
        "<h1>Part 2</h1></center>\n",
        "\n",
        "---\n",
        "\n",
        "With 243M downloads and 13K stars on GitHub - MLflow is one of the most widely adopted open-source tools for machine learning lifecycle management. It supports live logging of parameters, metrics, and artifacts, in addition to providing a Model Registry with Deployment functionality.\n",
        "\n",
        "We integrated MLflow into DagsHub almost two years ago, providing a zero-configuration remote MLflow Server with built-in access controls, that support MLflow's Tracking, Model Registry, and Deployment functionality. We've dived into its internals, handled many of its specifics, and now we want to share the knowledge we gained with the data science community!\n",
        "\n",
        "This webinar is the second part of our two-part virtual course and will cover some of the more advanced aspects of MLflow.\n",
        "\n",
        "If you missed the first part, you can check out the [recording here](https://youtu.be/daBTYQP23-A) on our [YouTube channel](https://www.youtube.com/c/DAGsHub)\n"
      ],
      "metadata": {
        "id": "nZMKAqKgzcIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DagsHub Integration\n",
        "\n",
        "<h4>\n",
        "In the session today, we will use DagsHub integration with MLflow. ‚ù§Ô∏è\n",
        "\n",
        "You will log and register models to a remote server and use that server to deploy those same models to AWS.\n",
        " \n",
        "For that, you will need to sign up for DagsHub (for free) üëá \n",
        "</h4>\n",
        "<center><h3><a href=\"https://bit.ly/3Sjl9UA\">Sign up to DagsHub</a></h3></center> \n",
        "\n",
        "<center><img src=\"https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco/plwmuai9t3okgwbuhkho\" height=\"200\"/></center>\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "<img src=\"https://dragonballz.co.il/wp-content/uploads/2020/12/discord-logo.jpg\" height=\"23\"/> [Discord Channel](https://discord.com/channels/698874030052212737/698874030572437526) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Linkedin.svg/1200px-Linkedin.svg.png\" height=\"23\"/> [LinkedIn](https://www.linkedin.com/company/dagshub/) | <img src=\"https://help.twitter.com/content/dam/help-twitter/brand/logo.png\" height=\"25\"/> [Twitter](https://twitter.com/TheRealDAGsHub) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Octicons-mark-github.svg/1200px-Octicons-mark-github.svg.png\" height=\"25\"/> [GitHub](https://github.com/DAGsHub) | <img src=\"\thttps://www.mlflow.org/docs/latest/_static/MLflow-logo-final-black.png\" height=\"30\"/> [MLFlow](https://www.mlflow.org/)"
      ],
      "metadata": {
        "id": "Gdp5XmeS_GeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5BYFe7ZkWKZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üòÇ Some memes to read while we wait\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi1.wp.com%2Fcdn-images-1.medium.com%2Fmax%2F1600%2F1*jBjJw7jq71pw4iZkqyp2Uw.jpeg%3Fresize%3D382%252C374%26ssl%3D1&f=1&nofb=1&ipt=21e3c5604890d80646e0afa0b82d616915675f93f012cf98f1db495e0bea1848&ipo=images\" height=\"\"/>\n",
        "<figcaption>If this ‚òùÔ∏è is you, don't worry, we're here to help!</figcaption></figure></center>\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F552%2F1*bBKm9MleM138jWYD8UbDFA.jpeg&f=1&nofb=1&ipt=689cf96f827ac9b03931012e6d7eefaf868467961e24cc4f2943a81291d13b45&ipo=images\" height=\"\"/>\n",
        "<figcaption>What problem?</figcaption></figure></center>\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://i.imgflip.com/6vshih.jpg\" height=\"\"/>\n",
        "<figcaption>üî•üî•üî•</figcaption></figure></center>\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://i.imgflip.com/6vshxs.jpg\" height=\"\"/>\n",
        "<figcaption>OPS SMASH!</figcaption></figure></center>"
      ],
      "metadata": {
        "id": "lcXEkAI44lcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Ü©Ô∏è Recap of MLflow 101\n",
        "\n",
        "In the first webinar, you learned about MLflow experiments, runs, and logging parameters, metrics, and artifacts.\n",
        "\n",
        "Shambhavi explained how she was able to replace the spreadsheets and Notion pages she used to track her machine learning experiments with a tool that was made for the job.\n",
        "\n",
        "</br>\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1xD1aR3-yZICt9vMIdIHkATBMBAS6Pcbx\" height=\"300\"/>\n",
        "</center>\n",
        "\n",
        "</br>\n",
        "\n",
        "If you recall, the concepts of experiments and runs are flexible and can depend on your situation and preferences. However, you can think of an **experiment** as a hypothesis you are testing while training your model. Each **experiment** can have one or more **runs**. During these runs you can log any parameters, metrics and artifacts you want to keep track of and compare later on.\n",
        "\n",
        "</br>\n",
        "\n",
        "When used this way, MLflow is your digital lab notebook!\n",
        "\n",
        "</br>\n",
        "\n",
        "Additionally, you'll recall the various scenarios available to you to run MLflow. When you use DagsHub's integration with MLflow, DagsHub does the heavy MLOps lifting for you. You get an MLflow Tracking Server enabled with proxied artifact storage access. \n",
        "\n",
        "</br>\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=17ERqAUwx7OUcph3EjPUPL4OoyCwuhh2W\" height=\"120%\"/>\n",
        "</center>\n",
        "\n",
        "</br>\n",
        "\n",
        "What's more, **DagsHub provides this remote MLflow server with every repository for free.**\n",
        "\n",
        "</br>\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1kDoJcbYj_mebQ-6Dh6aPe-OE5LNSvqsR\" height=\"150\"/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "2S19ylMOAahn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What Does MLflow 102 Cover?\n"
      ],
      "metadata": {
        "id": "Zy_h-a2UCg9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this follow up webinar, you‚Äôre going to expand your MLflow knowledge and learn about the **Model Registry**. You will:\n",
        "\n",
        "1. log and register models to the registry\n",
        "2. load models from the registry\n",
        "3. deploy a model to Amazon Sagemaker using the registry\n",
        "4. create a docker image, which can be used to deploy a model anywhere\n",
        "\n",
        "So let‚Äôs get started!"
      ],
      "metadata": {
        "id": "5Oz6e_5KBU8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why is Deployment Important to Learn?\n",
        "\n",
        "Machine learning models are only valuable, when they're deployed to production. If no one has access to the best machine learning model then it doesn't matter how good it is. Its value is derived from its use."
      ],
      "metadata": {
        "id": "sb-0HtjBodbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìì Model Registry\n",
        "\n"
      ],
      "metadata": {
        "id": "XC88XHiRhMrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model registry is a centralized store for your models. It provides a place to put models, related to experiments and runs and includes model versioning and stage transitions.\n",
        "\n",
        "</br>\n",
        "\n",
        "By keeping track of these things in the Model Registry, MLflow makes it easier for you to determine which model you need to deploy to which environment. It makes the whole process less prone to error.\n",
        "\n",
        "</br>\n",
        "\n",
        "The MLflow Model Registry has a few important concepts:\n",
        "\n",
        "</br>\n",
        "\n",
        "1. **Model**: created from experiment or run and logged using `mlflow.<framework>.log_model()`\n",
        "2. **Registered Model**: model registered with the Model Registry. Has a unique name, contains versions, associated transitional stages, model lineage, and other metadata.\n",
        "3. **Model Version**: Registered models have one or more versions. Initial version is 1. Version is auto-incremented when new models are registered using the same model name.\n",
        "4. **Model Stage**: Predefined as Staging, Production, Archived. Currently custom stages are not supported, but there is an open [feature request](https://github.com/mlflow/mlflow/issues/3686) to add this.\n",
        "5. **Annotations and Descriptions**: Use Markdown to annotate the top-level model or individual versions with any info you want or may be useful\n",
        "\n",
        "</br>\n",
        "\n",
        "There is a subtle difference between **logging** a model and **registering** a model. You can think of them in terms of their purpose. Logging a model is important for reproducibility. Registering a model is important for production. You can, however, log and register a model in one step.\n",
        "\n",
        "</br>\n",
        "\n",
        "And just as importantly, not only can you log and register models to your Model Registry... but you can **load** and **deploy** them!"
      ],
      "metadata": {
        "id": "PcHjXZnrBNnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><figure><img src=\"https://www.databricks.com/wp-content/uploads/2019/10/model-registry-new.png\" height=\"\"/>\n",
        "<figcaption></figcaption></figure></center>\n"
      ],
      "metadata": {
        "id": "WIxfyz2hA4tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÄ Updating\n",
        "\n",
        "Once you understand how these concepts fit together, you can even change specific aspects of registered models. \n",
        "\n",
        "You can change:\n",
        "\n",
        "1. Model name\n",
        "2. Model stage\n",
        "3. Model tags and attributes\n",
        "\n",
        "Of these, #2 is possibly the most important. This is how you will indicate a model has moved from **Staging** to **Production**, and keep your whole organization on the same page."
      ],
      "metadata": {
        "id": "t79UR1HzhqIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîé Searching\n",
        "\n",
        "The longer a project runs, the more experiments, runs, and registered models you will have.\n",
        "\n",
        "Keeping track of all of them would be a nightmare without the ability to search. \n",
        "\n",
        "</br>\n",
        "\n",
        "MLflow already addresses this problem and includes APIs to:\n",
        "\n",
        "1. Fetch a list of all registered models\n",
        "2. Search for models by exact or partial name using a SQL-like query format\n",
        "\n",
        "</br>\n",
        "\n",
        "Easy!"
      ],
      "metadata": {
        "id": "I8gJKKuyikC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Serving and Deploying\n"
      ],
      "metadata": {
        "id": "sZpAQeeTjdhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLflow offers options for both serving and deploying. The difference is a subtle but important one.\n",
        "\n",
        "Model serving uses the current machine, where as model deploying can be to any machine. Model deploying is also dependent on creating a Docker image."
      ],
      "metadata": {
        "id": "yVl8zQ8QBhX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üçΩÔ∏è Model Serving"
      ],
      "metadata": {
        "id": "VJrOTDepkfCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can serve your registered model locally using the CLI `mlflow serve`. By default this will serve a REST-API version of your model on port 5000. The inference endpoint is:\n",
        "\n",
        "```bash\n",
        "http://localhost:5000/invocations\n",
        "```\n",
        "\n",
        "Behind the hood, MLflow is using [Flask](https://flask.palletsprojects.com/) to create the web application."
      ],
      "metadata": {
        "id": "ID0iUZYMB5cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üö¢ Model Deploying"
      ],
      "metadata": {
        "id": "uhxLtZDPk9mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you‚Äôre ready to deploy a model, you have a few built in options. MLflow has built in support to deploy to [Amazon Sagemaker](https://aws.amazon.com/sagemaker/) and [Microsoft Azure](https://azure.microsoft.com/). \n",
        "\n",
        "</br>\n",
        "\n",
        "There are also 3rd party plugins available to deploy to:\n",
        "\n",
        "- RedisAI\n",
        "- TorchServe\n",
        "- Algorithmia\n",
        "- Ray Serve\n",
        "\n",
        "</br>\n",
        "\n",
        "If none of these services are your personal or professional preference for hosting your models, you have a couple of options:\n",
        "\n",
        "1. Write a custom deployment plugin following the examples above, **OR**\n",
        "2. Use MLflow to generate a Docker image, which wraps your model in a REST API\n",
        "\n",
        "</br>\n",
        "\n",
        "By creating a Docker image, you have the ultimate flexibility to take your model anywhere. By default this Docker image will use [nginx](https://nginx.org/) and [Gunicorn](https://gunicorn.org).\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1628683652155/a8TDdumkm.jpeg?auto=compress,format&format=webp\" height=\"\"/>\n",
        "<figcaption></figcaption></figure></center>\n",
        "\n",
        "</br>\n",
        "\n",
        "> **NOTE:** If you're unfamiliar with Docker, you can check out this [beginner friendly tutorial](https://wsvincent.com/beginners-guide-to-docker/). For the time being, just know that it is a way to build, test, and reproducably deploy applications using containers on a variety of hardware and software."
      ],
      "metadata": {
        "id": "T11_MtVbB-ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß¢ Recap of our sample project"
      ],
      "metadata": {
        "id": "MkLBEOWTX5qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you recall, we're working with a small sample model that can classify whether a video game frame contains **Mario** or his arch-rival **Wario**\n",
        "\n",
        "</br>\n",
        "\n",
        "<center><figure><img src=\"https://www.gamearter.com/games/super-mario-vs-wario/thumbnails/fbimage.jpg\" height=\"260\"/>\n",
        "<figcaption>Mario vs Wario</figcaption></figure></center>\n",
        "\n",
        "</br>\n",
        "\n",
        "\n",
        "But in our case, they look like this:\n",
        "\n",
        "<center><table>\n",
        "<tr>\n",
        "<td>\n",
        "<center><figure><img src=\"https://drive.google.com/uc?id=1qWgQ8xK8n1uUdT14bO2c3CjHgANnjo38\" height=\"200\"/>\n",
        "<figcaption>Mario</figcaption></figure></center>\n",
        "</td>\n",
        "<td>\n",
        "<center><figure><img src=\"https://drive.google.com/uc?id=1KAhtkkIlYMhywZmSQ0rw7LqhNei8NtfW\" height=\"200\"/>\n",
        "<figcaption>Wario</figcaption></figure></center>\n",
        "</td>\n",
        "</tr>\n",
        "</table></center>\n",
        "\n",
        "</br>\n"
      ],
      "metadata": {
        "id": "Ec_OEKk0XJnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë∑‚Äç‚ôÄÔ∏è Setup the project in Colab Runtime"
      ],
      "metadata": {
        "id": "6E4MGW5-FTE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DagsHub Configurations "
      ],
      "metadata": {
        "id": "wl78R8dPkRbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Enter the username of your DAGsHub account:\n",
        "DAGSHUB_USER_NAME = \"maulanaakbardj\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the email for your DAGsHub account:\n",
        "DAGSHUB_EMAIL = \"maulanaakbardwijaya@gmail.com\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ufslGlHVFYdc",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown DagsHub repo name to migrate and/or clone\n",
        "DAGSHUB_REPO_NAME = \"mario_vs_wario\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Name of branch to migrate and/or clone\n",
        "BRANCH = \"mlflow-102\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Do you want to start fresh from the canonical repo for this webinar? If you already have a DagsHub repo for this webinar, you must uncheck this box. Additionally, you should change the branch to `mlflow-101`, to match what is in your repo.\n",
        "START_FRESH = True #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "uw8Hr_-zFZAJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Generate an Access Token, for improved account security**"
      ],
      "metadata": {
        "id": "ugEEh97mPfCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import getpass\n",
        "import datetime\n",
        "\n",
        "r = requests.post('https://dagshub.com/api/v1/user/tokens', \n",
        "                  json={\"name\": f\"colab-token-{datetime.datetime.now()}\"}, \n",
        "                  auth=(DAGSHUB_USER_NAME, getpass.getpass('DAGsHub password:')))\n",
        "r.raise_for_status()\n",
        "DAGSHUB_TOKEN=r.json()['sha1']"
      ],
      "metadata": {
        "id": "9afz_9k6FqcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840f55dc-50ac-4680-9592-a3afe966c4f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAGsHub password:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Migrate the repository under your user with [DagsHub API](https://dagshub.com/docs/api)**"
      ],
      "metadata": {
        "id": "Fg-Q1mtJF0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if START_FRESH:\n",
        "    import json\n",
        "\n",
        "    user_data = requests.get(\"https://dagshub.com/api/v1/user/\",auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "    user = json.loads(user_data.text)\n",
        "\n",
        "    p = {\n",
        "      \"clone_addr\": f\"https://dagshub.com/nirbarazida/{DAGSHUB_REPO_NAME}.git\",\n",
        "      \"repo_name\": f\"{DAGSHUB_REPO_NAME}\",\n",
        "      \"user_id\":user[\"id\"],\n",
        "      \"mirror\": False,\n",
        "      \"visibility\": \"public\",\n",
        "    }\n",
        "\n",
        "    r = requests.post(\"https://dagshub.com/api/v1/repos/migrate\", data=p, auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "    if r.status_code == 201:\n",
        "      print(\"Migration succeeded\")\n",
        "    else:\n",
        "      print(\"Migration faild with error:\\n\", r.text)"
      ],
      "metadata": {
        "id": "EoUs9aPUFtgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f093bd-f228-48d9-e3bb-416db1784e98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migration succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è¨ Clone the Project and Pull the data to Colab Runtime"
      ],
      "metadata": {
        "id": "MU7dNou0F9m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure Git**"
      ],
      "metadata": {
        "id": "QQsYUtDwGE1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {DAGSHUB_EMAIL}\n",
        "!git config --global user.name {DAGSHUB_USER_NAME}"
      ],
      "metadata": {
        "id": "NkYJ39OXF7WK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the Repository**"
      ],
      "metadata": {
        "id": "Rd02jjRRGGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b {BRANCH} https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.git\n",
        "\n",
        "if not START_FRESH:\n",
        "    !git clone -b mlflow-102 https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/nirbarazida/{DAGSHUB_REPO_NAME}.git temp_repo\n",
        "    !cp temp_repo/src/get_last_run_id.py {DAGSHUB_REPO_NAME}/src/\n",
        "    !cp temp_repo/src/register_pyfunc.py {DAGSHUB_REPO_NAME}/src/\n",
        "\n",
        "%cd {DAGSHUB_REPO_NAME}"
      ],
      "metadata": {
        "id": "Og48wUBwGASF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccb93f3-bf0b-48fa-8b7d-48601ad665bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mario_vs_wario'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 81 (delta 23), reused 81 (delta 23), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n",
            "/content/mario_vs_wario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install and Configure DVC**\n",
        "\n",
        "DVC is a fantastic tool that version controls your data and model artifacts. You don't need to know about DVC for this workshop, but if you're interested in more information, [check out our documentation](https://dagshub.com/docs/integration_guide/dvc/)."
      ],
      "metadata": {
        "id": "TTjjspauGSh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dvc>=2.18.0 --quiet\n",
        "\n",
        "# Import DVC package (relevant only when working in a Colab environment)\n",
        "import dvc\n",
        "\n",
        "# General DVC user configuration\n",
        "!dvc remote modify --local origin auth basic\n",
        "!dvc remote modify --local origin user {DAGSHUB_USER_NAME}\n",
        "!dvc remote modify --local origin password {DAGSHUB_TOKEN}\n",
        "\n",
        "!dvc pull -r origin >& dev_null\n",
        "\n",
        "# Make sure that all files were pulled\n",
        "!dvc pull -r origin >& dev_null"
      ],
      "metadata": {
        "id": "ZPiFDLLtGKLj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è≥ Install MLflow\n",
        "MLflow is installed using pip. \n",
        "\n",
        "*Note*: MLflow has several types of versions, each with different support. \n",
        "\n",
        "* Install MLflow\n",
        "\n",
        "  `pip install mlflow`\n",
        "\n",
        "* Install MLflow with the experimental MLflow Pipelines component\n",
        "\n",
        "  `pip install mlflow[pipelines]`\n",
        "\n",
        "* Install MLflow with extra ML libraries and 3rd-party tools\n",
        "\n",
        "  `pip install mlflow[extras]`\n",
        "\n",
        "* Install a lightweight version of MLflow\n",
        "    \n",
        "    `pip install mlflow-skinny`"
      ],
      "metadata": {
        "id": "d5DIqa7EGqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet"
      ],
      "metadata": {
        "id": "3grGRw_ZGn1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d42ba6-6216-4a5b-96ba-73f1945b0807"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.9 MB 1.0 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147 kB 40.0 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 5.5 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 209 kB 38.4 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79 kB 7.1 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78 kB 9.1 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 3.7 MB/s \n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59 kB 8.5 MB/s \n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up environment variables "
      ],
      "metadata": {
        "id": "n7dMW_MK7uTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# TODO: Explain that it's recommended to define this in the code because it's project specific\n",
        "os.environ['MLFLOW_TRACKING_URI']=f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.mlflow\"\n",
        "\n",
        "# Recommended to define as environment variables\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN"
      ],
      "metadata": {
        "id": "29SxyrPY71NU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow"
      ],
      "metadata": {
        "id": "mGsJo5lO2b8D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèãÔ∏è‚Äç‚ôÇÔ∏è Initial training"
      ],
      "metadata": {
        "id": "FkDMtajn_iI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we're going to rerun the training script as it was at the end of MLflow Webinar 101. This will train a model, log some parameters, log some metrics, and log the model artifacts."
      ],
      "metadata": {
        "id": "nuA0-k_lYcSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/mario_vs_wario/src/train.py"
      ],
      "metadata": {
        "id": "y1hKge4V_l7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c6eaf8-22ea-4c96-d5ea-e28e712fb860"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 605ms/step - loss: 0.7305 - accuracy: 0.5514 - val_loss: 0.6853 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 512ms/step - loss: 0.6890 - accuracy: 0.5140 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.6871 - accuracy: 0.5701 - val_loss: 0.6778 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.6752 - accuracy: 0.5888 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 0.6878 - accuracy: 0.5888 - val_loss: 0.6736 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.6733 - accuracy: 0.5888 - val_loss: 0.6546 - val_accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 509ms/step - loss: 0.6832 - accuracy: 0.5514 - val_loss: 0.6522 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.6648 - accuracy: 0.5888 - val_loss: 0.6564 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.6552 - accuracy: 0.5888 - val_loss: 0.6524 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 518ms/step - loss: 0.6445 - accuracy: 0.5981 - val_loss: 0.6250 - val_accuracy: 0.5600\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.6876 - accuracy: 0.4667\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll run a script that gets the last run ID for the current experiment (named `mario_wario`) and stores it into an environment variable called `RUN_ID`.\n",
        "\n",
        "This will be used soon!"
      ],
      "metadata": {
        "id": "ttO0WFIkcp-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/mario_vs_wario/src/get_last_run_id.py RUN_ID"
      ],
      "metadata": {
        "id": "e-Q3RCKzL0w8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f602d5-a1a5-4cb8-c4a1-70e53fcf63f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 4bc143cdafc3454b8a056afe2327326c to environment variable RUN_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow runs list --experiment-id 0"
      ],
      "metadata": {
        "id": "iD6-ik_FA_IP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b40ee40-3b01-4063-b47d-23c0a055c9d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date                     Name    ID                              \n",
            "-----------------------  ------  --------------------------------\n",
            "2022-10-13 04:45:21 UTC          4bc143cdafc3454b8a056afe2327326c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging Models\n",
        "\n",
        "There are a couple of programmatic methods to log models\n",
        "\n"
      ],
      "metadata": {
        "id": "Gexe-41n4Occ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. `mlflow.register_model()`\n",
        "\n",
        "Use after runs have completed and you want to register a model after the fact.\n"
      ],
      "metadata": {
        "id": "bvA8XtSVBoiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import os\n",
        "\n",
        "# Grab the run ID from our environment variable\n",
        "run_id = os.environ['RUN_ID']\n",
        "\n",
        "# Select a subpath name for the run\n",
        "subpath = \"world_1-1\"\n",
        "\n",
        "# Select a name for the model to be registered\n",
        "model_name = \"Cool Mario Model\"\n",
        "\n",
        "# build the run URI\n",
        "run_uri = f'runs:/{run_id}/{subpath}'\n",
        "\n",
        "# register the model\n",
        "model_version = mlflow.register_model(run_uri, model_name)\n"
      ],
      "metadata": {
        "id": "aoHDlOqXB4_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28d01d9-98c2-4a76-e665-d0ef47257ff3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'Cool Mario Model'.\n",
            "2022/10/13 04:47:46 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Cool Mario Model, version 1\n",
            "Created version '1' of model 'Cool Mario Model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. `mlflow.<framework>.log_model()`\n",
        "\n",
        "Logs and registers the model simultaneously -- best done from the **train.py** script directly after training.\n",
        "\n",
        "In **train.py**, find the line of code on line 142 (`mlflow.log_artifact(MODELS_DIR`) and replace it with the following line:\n",
        "\n",
        "```python\n",
        "mlflow.keras.log_model(keras_model=model,\n",
        "                       artifact_path=MODELS_DIR,\n",
        "                       registered_model_name=\"Ultimate Mario Model\")\n",
        "```"
      ],
      "metadata": {
        "id": "7VKHga5AdNVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/mario_vs_wario/src/train.py"
      ],
      "metadata": {
        "id": "n-hYR_OheGlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d309094a-f769-4391-c3e0-d6ec8999b295"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 3s 581ms/step - loss: 0.7058 - accuracy: 0.5327 - val_loss: 0.6834 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6848 - accuracy: 0.5794 - val_loss: 0.6773 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6829 - accuracy: 0.5701 - val_loss: 0.6717 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 4s 915ms/step - loss: 0.6804 - accuracy: 0.5888 - val_loss: 0.6667 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 515ms/step - loss: 0.6818 - accuracy: 0.6075 - val_loss: 0.6647 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 524ms/step - loss: 0.6490 - accuracy: 0.6542 - val_loss: 0.6332 - val_accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.6606 - accuracy: 0.6168 - val_loss: 0.6158 - val_accuracy: 0.8400\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 0.6773 - accuracy: 0.6075 - val_loss: 0.6578 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.6590 - accuracy: 0.6262 - val_loss: 0.6286 - val_accuracy: 0.5600\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.6045 - accuracy: 0.7196 - val_loss: 0.5959 - val_accuracy: 0.7200\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5214 - accuracy: 0.7111\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
            "2022/10/13 04:50:30 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp0t5o313r/model, flavor: keras), fall back to return ['tensorflow==2.9.2', 'keras==2.9.0']. Set logging level to DEBUG to see the full traceback.\n",
            "Successfully registered model 'Ultimate Mario Model'.\n",
            "2022/10/13 04:50:35 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Ultimate Mario Model, version 1\n",
            "Created version '1' of model 'Ultimate Mario Model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîé Searching Models"
      ],
      "metadata": {
        "id": "RKvo4o-GgDq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we've only registered a couple of models, but can still test out MLflow's searching API"
      ],
      "metadata": {
        "id": "pZbbV3rS_814"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch all registered models"
      ],
      "metadata": {
        "id": "meiKQrgCgaQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a client to access the MLflow tracking server\n",
        "client = mlflow.MlflowClient()\n",
        "\n",
        "# loop through all registered models\n",
        "# NOTE: `filter_string` should be optional, but leaving it as `None` failed to work. \n",
        "# Instead, using `\"name LIKE '%'\"` will match all model names\n",
        "for model in client.search_registered_models(filter_string=\"name LIKE '%'\"):\n",
        "    # loop through the latest versions for each stage of a registered model\n",
        "    for model_version in model.latest_versions:\n",
        "        print(f\"name={model_version.name}; run_id={model_version.run_id}; version={model_version.version}, stage={model_version.current_stage}\")"
      ],
      "metadata": {
        "id": "TJoVG4Nngf8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b9d330-ba3a-4362-8a94-bb254ca99751"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name=Cool Mario Model; run_id=4bc143cdafc3454b8a056afe2327326c; version=1, stage=None\n",
            "name=Ultimate Mario Model; run_id=c5cd6556687c49b6b9536679902453b0; version=1, stage=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query specific registered models"
      ],
      "metadata": {
        "id": "oS9aWgtvkS3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = mlflow.MlflowClient()\n",
        "\n",
        "# loop through any registered model, whose name starts with `Cool`\n",
        "for model in client.search_registered_models(filter_string=\"name LIKE 'Cool%'\"):\n",
        "    for model_version in model.latest_versions:\n",
        "        print(f\"name={model_version.name}; run_id={model_version.run_id}; version={model_version.version}, stage={model_version.current_stage}\")"
      ],
      "metadata": {
        "id": "NVFRTa5tlKqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81da46ae-55d6-4fe2-acd9-3bf31fbf2363"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name=Cool Mario Model; run_id=4bc143cdafc3454b8a056afe2327326c; version=1, stage=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úèÔ∏è Update Model Information"
      ],
      "metadata": {
        "id": "XUZsdWhwnNVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating a model is important. Besides being able to update the name of a model or model tags, possibly the most important attribute you can update is the model stage."
      ],
      "metadata": {
        "id": "jPeckN2UBeCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rename a Model"
      ],
      "metadata": {
        "id": "wTAMn5uSnbjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a client to access the MLflow tracking server\n",
        "client = mlflow.MlflowClient()\n",
        "\n",
        "# rename the model from `Ultimate Mario Model` to `Great Mario Model`\n",
        "client.rename_registered_model(\n",
        "    name='Ultimate Mario Model', \n",
        "    new_name='Great Mario Model'\n",
        ")"
      ],
      "metadata": {
        "id": "wO3DcZQ0nRzc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update Stage\n"
      ],
      "metadata": {
        "id": "BNYkPMMbn7cY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# create a client to access the MLflow tracking server\n",
        "client = mlflow.MlflowClient()\n",
        "\n",
        "# transition version 1 of the `Great Mario Model` model from `None` to `Staging`\n",
        "client.transition_model_version_stage(\n",
        "    name='Great Mario Model',\n",
        "    version=1,\n",
        "    stage=\"Staging\"\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "AVY01QK9n_p6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While you could update those attributes using MLflow's Python API as shown above, why not do it through the MLflow Tracking Server's web UI?"
      ],
      "metadata": {
        "id": "qGGIC9YzDEeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.mlflow\")"
      ],
      "metadata": {
        "id": "u1Hdy725C6oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fac3d9-cdaa-426c-d1eb-c2b002c17880"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://dagshub.com/maulanaakbardj/mario_vs_wario.mlflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And just to verify that we see those changes here, too..."
      ],
      "metadata": {
        "id": "Vqx9mXkIH2OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = mlflow.MlflowClient()\n",
        "for model in client.search_registered_models(filter_string=\"name LIKE 'Great%'\"):\n",
        "    for model_version in model.latest_versions:\n",
        "        print(f\"name={model_version.name}; run_id={model_version.run_id}; version={model_version.version}, stage={model_version.current_stage}\")"
      ],
      "metadata": {
        "id": "LBLArilRo48Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4260f791-23b4-4c22-c8a2-5c37f9b7982b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name=Great Mario Model; run_id=c5cd6556687c49b6b9536679902453b0; version=1, stage=Staging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Loading Models\n",
        "\n",
        "To load a model, you need to first construct the model URI, which has the format:\n",
        "\n",
        "```\n",
        "models:/<model name>/<model version>\n",
        "```\n",
        "\n",
        "or alternatively:\n",
        "\n",
        "```\n",
        "models:/<model name>/<model stage>\n",
        "```"
      ],
      "metadata": {
        "id": "Akz-QLRGlTzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model name\n",
        "name = 'Great Mario Model'\n",
        "\n",
        "# Get the latest version for the model\n",
        "version = client.get_latest_versions(name=name)[0].version\n",
        "\n",
        "# Construct the model URI\n",
        "model_uri = f'models:/{name}/{version}'\n",
        "\n",
        "# Load the model\n",
        "model = mlflow.keras.load_model(model_uri)"
      ],
      "metadata": {
        "id": "uL8dsdIKl4-o"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have a model loaded, we should test it to make sure it works"
      ],
      "metadata": {
        "id": "wLNNor_rm9M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def load_test_image():\n",
        "    '''Loads an image from the test dataset and prepares it for inference'''\n",
        "    img_path = 'data/processed/test/mario/mario_0.jpg'\n",
        "    \n",
        "    # Load the image as in PIL format using keras's helper functions\n",
        "    img = keras.preprocessing.image.load_img(img_path, color_mode='grayscale', target_size=(128, 128))\n",
        "\n",
        "    # Convert the PIL image to a numpy array\n",
        "    X = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Normalize the pixel values\n",
        "    X = X / 255.0\n",
        "\n",
        "    # Expand the dimensions to include a batch dimension\n",
        "    X = tf.expand_dims(X, axis=0)\n",
        "\n",
        "    return X\n",
        "\n",
        "X = load_test_image()\n",
        "\n",
        "# Run inference\n",
        "model(X)"
      ],
      "metadata": {
        "id": "lkEu0MWKmcEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79899242-1be4-4f30-86ac-d07da308e3e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6991703]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§∑ What if you don't use Keras?\n",
        "\n",
        "There are many other supported frameworks, but what if you have a special case?\n",
        "\n",
        "MLflow has support for generic Python functions!"
      ],
      "metadata": {
        "id": "MDG9bqWxpLJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To support logging of generic Python functions you need to:\n",
        "\n",
        "1. Create a wrapper class that inherits from `mlflow.pyfunc.PythonModel`.\n",
        "2. Write a `predict` method, which takes the `context` and the `model_input`.\n",
        "3. Optionally write a `load_context` method to setup your model."
      ],
      "metadata": {
        "id": "j6ngs18uqHQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy this example wrapper for our Mario vs Wario model to the end of **register_pyfunc.py**:\n",
        "\n",
        "```python\n",
        "# Our wrapper class needs to inhert from mlflow.pyfunc.PythonModel\n",
        "class MarioModelWrapper(mlflow.pyfunc.PythonModel):\n",
        "    from tensorflow import keras\n",
        "\n",
        "    # Use `load_context` to initialize your model. This will only be run once.\n",
        "    def load_context(self, context):\n",
        "        self.model = keras.models.load_model(context.artifacts[\"path\"])\n",
        "\n",
        "    # You **must** include a `predict` method, which takes a context and a model input\n",
        "    def predict(self, context, model_input):\n",
        "        import io\n",
        "        import base64\n",
        "        \n",
        "        # model_input is a numpy array of a base64 string (in this case)\n",
        "        # to convert to a useable format we need to:\n",
        "        #     1. convert the base64 string into bytes\n",
        "        #     2. decode the base64 bytes into image bytes\n",
        "        #     3. create an IO buffer with those image bytes\n",
        "        input_bytes = model_input.tobytes()\n",
        "        img_bytes = base64.b64decode(input_bytes)\n",
        "        buf = io.BytesIO(img_bytes)\n",
        "\n",
        "        # we can use the buffer as an input to keras's `load_img` function,\n",
        "        # which will decode the JPEG image bytes into pixels\n",
        "        img = keras.preprocessing.image.load_img(buf, color_mode='grayscale', target_size=(128, 128))\n",
        "\n",
        "        # convert the image into a numpy array\n",
        "        X = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "        # normalize the pixel values\n",
        "        X = X / 255.0\n",
        "\n",
        "        # expand the dimensions to include the batch dimension\n",
        "        X = tf.expand_dims(X, axis=0)\n",
        "\n",
        "        # run inference and extract the single value result\n",
        "        result = self.model(X).numpy().tolist()[0][0]\n",
        "\n",
        "        # return the result as a dictionary, which can be converted to JSON\n",
        "        return {\"result\": result}\n",
        "\n"
      ],
      "metadata": {
        "id": "kToypcZ5qpNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, you need to setup a `conda_env` dictionary, so MLflow knows what libraries are needed to run the model.\n",
        "\n",
        "Copy the following after your wrapper definition:\n",
        "\n",
        "```python\n",
        "PYTHON_VERSION = \"{major}.{minor}.1\".format(major=version_info.major,\n",
        "                                            minor=version_info.minor)\n",
        "\n",
        "conda_env = {\n",
        "    'channels': ['defaults'],\n",
        "    'dependencies': [\n",
        "        'python~={}'.format(PYTHON_VERSION),\n",
        "        'pip',\n",
        "          {\n",
        "            'pip': [\n",
        "                'mlflow',\n",
        "                'pillow',\n",
        "                'cloudpickle=={}'.format(cloudpickle.__version__),\n",
        "                'tensorflow>={}'.format(tf.__version__)\n",
        "            ],\n",
        "          },\n",
        "    ],\n",
        "    'name': 'mario_env'\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "k2ZhMdMcrHGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You also need to set up an artifacts dictionary, which will be part of the `context` your wrapper class receives. \n",
        "\n",
        "Copy this code after the `conda_env` setup dictionary:\n",
        "\n",
        "```python\n",
        "artifacts = {\n",
        "    'path': MODELS_DIR\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "WcrZ4b4arfws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you need to instantiate the wrapper class and log the model.\n",
        "\n",
        "Copy all of this to the end of **register_pyfunc.py**:\n",
        "\n",
        "```python\n",
        "# instantiate the model wrapper\n",
        "model = MarioModelWrapper()\n",
        "\n",
        "# get the experiment ID for our current experiment\n",
        "exp_id = get_experiment_id(\"mario_wario\")\n",
        "\n",
        "with mlflow.start_run(experiment_id=exp_id):\n",
        "    # log the Python function model\n",
        "    mlflow.pyfunc.log_model(\n",
        "        \"world_1-4\", \n",
        "        python_model=model, \n",
        "        conda_env=conda_env, \n",
        "        artifacts=artifacts, \n",
        "        registered_model_name=\"Wicked Wario Model\",\n",
        "    )\n",
        "```"
      ],
      "metadata": {
        "id": "2pdB2faDsFqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run that code!"
      ],
      "metadata": {
        "id": "gcD3fbOEt07a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/mario_vs_wario/src/register_pyfunc.py"
      ],
      "metadata": {
        "id": "LWLdFurCt4YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e23c85a-bd16-450f-8276-d446bfdc3bc6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'Wicked Wario Model'.\n",
            "2022/10/13 05:06:17 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Wicked Wario Model, version 1\n",
            "Created version '1' of model 'Wicked Wario Model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make sure our Wicked Wario Model has been registered"
      ],
      "metadata": {
        "id": "i-SKf52ZRl4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = mlflow.MlflowClient()\n",
        "for model in client.search_registered_models(filter_string=\"name LIKE '%'\"):\n",
        "    for model_version in model.latest_versions:\n",
        "        print(f\"name={model_version.name}; run_id={model_version.run_id}; version={model_version.version}, stage={model_version.current_stage}\")"
      ],
      "metadata": {
        "id": "CLYyidBfuKJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27acc5c1-2a9a-45f6-e014-4d83c8b17ac2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name=Cool Mario Model; run_id=4bc143cdafc3454b8a056afe2327326c; version=1, stage=None\n",
            "name=Great Mario Model; run_id=c5cd6556687c49b6b9536679902453b0; version=1, stage=Staging\n",
            "name=Wicked Wario Model; run_id=28b1c062c01f426eb29c723c391f7faf; version=1, stage=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Deploying Model to Amazon SageMaker"
      ],
      "metadata": {
        "id": "AWMqgZwRumew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you can start with Amazon SageMaker, you need to make sure you create and setup your AWS account properly.\n",
        "\n",
        "1. [How to Create an AWS Account](https://aws.plainenglish.io/getting-started-to-aws-creating-an-aws-account-b11d685cbeea) <- you will need a credit card\n",
        "2. [Setup IAM (Identity and Access Management) Role(s)](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html)\n",
        "3. Install the AWS CLI using `pip install awscli`\n",
        "4. Add your credentials to `~/.aws/credentials`\n",
        "\n",
        "Your credentials file should look like this:\n",
        "\n",
        "```\n",
        "[default]\n",
        "aws_access_key_id = ***\n",
        "aws_secret_access_key = ***\n",
        "```\n"
      ],
      "metadata": {
        "id": "UdYypXOGleGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following command only needs to be run once for each AWS account. It creates the docker image that gets used by MLflow to serve the model and pushes it to Amazon SageMaker.\n",
        "\n",
        "```\n",
        "mlflow sagemaker build-and-push-container\n",
        "```"
      ],
      "metadata": {
        "id": "cC7Aygqyu5N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To deploy, you need to know:\n",
        "\n",
        "1. Your SageMaker execution role\n",
        "2. The AWS region you are going to deploy the endpoint to\n",
        "\n",
        "```\n",
        "mlflow sagemaker deploy --app-name mario \\\n",
        "                        --model-uri \"models:/Best Mario Model/1\" \\\n",
        "                        -e arn:aws:iam::***:role/SageMakerRole \\\n",
        "                        --region-name us-east-2 \n",
        "```"
      ],
      "metadata": {
        "id": "WMguiOe1a9x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üê≥ Creating Docker Images\n",
        "\n",
        "You can also use MLflow to create docker images to deploy anywhere you want.\n",
        "\n",
        "```\n",
        "mlflow models build-docker --name mario \\\n",
        "                           --model-uri \"models:/Best Mario Model/1\"\n",
        "```\n",
        "\n",
        "After this, you can spin up a docker container with this image.\n",
        "\n",
        "```\n",
        "docker run -d -p 8080:8080 mario:latest\n",
        "```"
      ],
      "metadata": {
        "id": "dS3qW79Ab28o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Running inference"
      ],
      "metadata": {
        "id": "oLnC62ZAUMM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run inference using our Docker container with a `curl` command.\n",
        "\n",
        "The image input, as discussed, will need to be a base64 encoded image. But we can't just send the base64 string. We need to include it in a JSON dictionary with this format:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"inputs\": \"base64-string-representation-of-image...\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "Hw4ylGiEUjY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our `bash` command, which uses the built in `base64` command to convert our image into a string"
      ],
      "metadata": {
        "id": "7LZGRb4bV45C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "curl http://localhost:8080/invocations \\\n",
        "        -H 'Content-Type: application/json' \\\n",
        "        -d '{\"inputs\": \"'$(base64 -w 0 mario_0.jpg)'\"}' \n",
        "```"
      ],
      "metadata": {
        "id": "X3pgR1cmU1Jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XE_ZguaHo4mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typical Errors"
      ],
      "metadata": {
        "id": "pc8eQWRMmHYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yaml.representer.RepresenterError"
      ],
      "metadata": {
        "id": "fIbEUSdgmSHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "yaml.representer.RepresenterError: ('cannot represent an object', <__main__.MarioModelWrapper object at 0x105772f70>)\n",
        "```\n",
        "\n",
        "**Solution:** Check that your `conda_env` is properly set and is a type that can be converted to YAML"
      ],
      "metadata": {
        "id": "GwuG8kPumKov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Registry features are not supported by the store with URI"
      ],
      "metadata": {
        "id": "G90suLC5migV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "mlflow.exceptions.MlflowException: Model Registry features are not supported by the store with URI: \n",
        "'file:///Users/***/repos/mario_vs_wario_102/mlruns'. Stores with the following URI schemes are supported: \n",
        "['databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql'].\n",
        "```\n",
        "\n",
        "**Solution:** Ensure that you've set your tracking URI or have saved a model locally"
      ],
      "metadata": {
        "id": "GFNQthQTmqRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using an MLflow command that takes a `model_uri`"
      ],
      "metadata": {
        "id": "C_lNPjkWnJRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "mlflow.exceptions.RestException: RESOURCE_DOES_NOT_EXIST: \n",
        "Response: {'error_code': 'RESOURCE_DOES_NOT_EXIST'}\n",
        "```\n",
        "\n",
        "**Solution:** Either the model name is incorrect or the version number doesn't exist. \n"
      ],
      "metadata": {
        "id": "8NkTkQsXnRJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploying to Amazon SageMaker"
      ],
      "metadata": {
        "id": "PQ1eCXNmoiP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "The repository with name 'mlflow-pyfunc' does not exist in the registry with id '***'\n",
        "```\n",
        "\n",
        "**Solution 1:** Run `mlflow sagemaker build-and-push-container` first\n",
        "\n",
        "**Solution 2:** Specify the SageMaker execution role in your command"
      ],
      "metadata": {
        "id": "jdKlq0spomgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "The role with name *** cannot be found.\n",
        "``` \n",
        "\n",
        "**Solution:** Specify the region name"
      ],
      "metadata": {
        "id": "8BAvnDU2ouUE"
      }
    }
  ]
}